{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2964163",
   "metadata": {},
   "source": [
    "Try WordNet for creating specificity manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d658f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169da272",
   "metadata": {},
   "source": [
    "WordNet implemented here has the ability to find hypernyms (more general) and hyponyms (more specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0b3689c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('basenji.n.01'),\n",
       " Synset('corgi.n.01'),\n",
       " Synset('cur.n.01'),\n",
       " Synset('dalmatian.n.02'),\n",
       " Synset('great_pyrenees.n.01'),\n",
       " Synset('griffon.n.02'),\n",
       " Synset('hunting_dog.n.01'),\n",
       " Synset('lapdog.n.01'),\n",
       " Synset('leonberg.n.01'),\n",
       " Synset('mexican_hairless.n.01'),\n",
       " Synset('newfoundland.n.01'),\n",
       " Synset('pooch.n.01'),\n",
       " Synset('poodle.n.01'),\n",
       " Synset('pug.n.01'),\n",
       " Synset('puppy.n.01'),\n",
       " Synset('spitz.n.01'),\n",
       " Synset('toy_dog.n.01'),\n",
       " Synset('working_dog.n.01')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog', pos=wn.NOUN)[0].hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3fd852",
   "metadata": {},
   "source": [
    "One idea: \n",
    "1. Since we have three levels of specificity (low, mid, high), for the 'mid' level, we sample nouns that are of various frequencies/age of acquisition/lengths\n",
    "2. Then for each of those words, we find a corresponding hyponym and a hypernym, creating our triad\n",
    "3. The resulting triads should have distributions whose locations are incrementally higher (low < mid < high), but on the whole at least we have 'low' words that are low frequency, and 'high' words that are high frequency\n",
    "Would this work? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd0e0cf",
   "metadata": {},
   "source": [
    "Actually, use LexOps to find pairs that different in frequencies, perhaps whose locations are quite close, whilst matching concreteness, age of acquisition, lexical decision. Then use the low frequency side to find hypernyms, and high frequency side to find hyponyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87a1108c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_nr</th>\n",
       "      <th>condition</th>\n",
       "      <th>match_null</th>\n",
       "      <th>string</th>\n",
       "      <th>Zipf.SUBTLEX_UK</th>\n",
       "      <th>AoA.Kuperman</th>\n",
       "      <th>CNC.Brysbaert</th>\n",
       "      <th>RT.BLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>LowFreq</td>\n",
       "      <td>A1</td>\n",
       "      <td>earphone</td>\n",
       "      <td>1.649978</td>\n",
       "      <td>9.45</td>\n",
       "      <td>4.74</td>\n",
       "      <td>613.184210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>HighFreq</td>\n",
       "      <td>A1</td>\n",
       "      <td>cocoon</td>\n",
       "      <td>2.841864</td>\n",
       "      <td>8.95</td>\n",
       "      <td>4.83</td>\n",
       "      <td>598.351351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LowFreq</td>\n",
       "      <td>A1</td>\n",
       "      <td>tuft</td>\n",
       "      <td>2.451611</td>\n",
       "      <td>9.87</td>\n",
       "      <td>3.85</td>\n",
       "      <td>699.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>HighFreq</td>\n",
       "      <td>A1</td>\n",
       "      <td>pauper</td>\n",
       "      <td>2.897133</td>\n",
       "      <td>9.44</td>\n",
       "      <td>3.80</td>\n",
       "      <td>680.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>LowFreq</td>\n",
       "      <td>A2</td>\n",
       "      <td>goggle</td>\n",
       "      <td>2.348948</td>\n",
       "      <td>9.44</td>\n",
       "      <td>4.42</td>\n",
       "      <td>623.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>118</td>\n",
       "      <td>HighFreq</td>\n",
       "      <td>A1</td>\n",
       "      <td>uproar</td>\n",
       "      <td>2.913220</td>\n",
       "      <td>9.55</td>\n",
       "      <td>3.00</td>\n",
       "      <td>666.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>119</td>\n",
       "      <td>LowFreq</td>\n",
       "      <td>A1</td>\n",
       "      <td>thinness</td>\n",
       "      <td>2.158134</td>\n",
       "      <td>7.78</td>\n",
       "      <td>2.76</td>\n",
       "      <td>622.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>119</td>\n",
       "      <td>HighFreq</td>\n",
       "      <td>A1</td>\n",
       "      <td>coolness</td>\n",
       "      <td>2.625155</td>\n",
       "      <td>7.90</td>\n",
       "      <td>2.67</td>\n",
       "      <td>625.405405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>120</td>\n",
       "      <td>LowFreq</td>\n",
       "      <td>A2</td>\n",
       "      <td>floorboard</td>\n",
       "      <td>2.411739</td>\n",
       "      <td>9.35</td>\n",
       "      <td>4.89</td>\n",
       "      <td>671.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>120</td>\n",
       "      <td>HighFreq</td>\n",
       "      <td>A2</td>\n",
       "      <td>nozzle</td>\n",
       "      <td>2.874713</td>\n",
       "      <td>9.32</td>\n",
       "      <td>4.91</td>\n",
       "      <td>652.114286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     item_nr condition match_null      string  Zipf.SUBTLEX_UK  AoA.Kuperman  \\\n",
       "0          1   LowFreq         A1    earphone         1.649978          9.45   \n",
       "1          1  HighFreq         A1      cocoon         2.841864          8.95   \n",
       "2          2   LowFreq         A1        tuft         2.451611          9.87   \n",
       "3          2  HighFreq         A1      pauper         2.897133          9.44   \n",
       "4          3   LowFreq         A2      goggle         2.348948          9.44   \n",
       "..       ...       ...        ...         ...              ...           ...   \n",
       "235      118  HighFreq         A1      uproar         2.913220          9.55   \n",
       "236      119   LowFreq         A1    thinness         2.158134          7.78   \n",
       "237      119  HighFreq         A1    coolness         2.625155          7.90   \n",
       "238      120   LowFreq         A2  floorboard         2.411739          9.35   \n",
       "239      120  HighFreq         A2      nozzle         2.874713          9.32   \n",
       "\n",
       "     CNC.Brysbaert      RT.BLP  \n",
       "0             4.74  613.184210  \n",
       "1             4.83  598.351351  \n",
       "2             3.85  699.962963  \n",
       "3             3.80  680.580645  \n",
       "4             4.42  623.083333  \n",
       "..             ...         ...  \n",
       "235           3.00  666.277778  \n",
       "236           2.76  622.454545  \n",
       "237           2.67  625.405405  \n",
       "238           4.89  671.285714  \n",
       "239           4.91  652.114286  \n",
       "\n",
       "[240 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexops = pd.read_csv('lexops_output_frequency_manipulation.csv')\n",
    "lexops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "57f6da74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         string                hypernym\n",
      "51         grit               sandstone\n",
      "71      plywood                laminate\n",
      "75        chime   percussion_instrument\n",
      "217     transit    surveying_instrument\n",
      "139        gall          animal_disease\n",
      "182    molehill                   knoll\n",
      "145      martyr                  victim\n",
      "142    soreness                    pain\n",
      "175      mantel                   shelf\n",
      "107      damper                   plate\n",
      "181    preacher               clergyman\n",
      "134    bootlace                    lace\n",
      "190       colic                    pain\n",
      "232     checkup             examination\n",
      "31       seesaw               plaything\n",
      "114     slobber                  saliva\n",
      "88   sculptress                sculptor\n",
      "27        broom      cleaning_implement\n",
      "66    nursemaid                  keeper\n",
      "136      stanza                    text\n",
      "213     showman                  person\n",
      "60      corsage      flower_arrangement\n",
      "118    conclave                 meeting\n",
      "94       cutlet                   piece\n",
      "225        putt             golf_stroke\n",
      "147     snorkel        breathing_device\n",
      "148        cowl     protective_covering\n",
      "153        loin                     cut\n",
      "218      tampon                    plug\n",
      "57     lamppost                    post\n",
      "223      bistro              restaurant\n",
      "221     cobbler                   maker\n",
      "85     forklift  self-propelled_vehicle\n",
      "98    headboard                   panel\n",
      "8     harshness               roughness\n",
      "191     trustee               fiduciary\n",
      "125      damsel                    maid\n",
      "180    songbook                    book\n",
      "162     sprayer                 laborer\n",
      "208   birthmark                 blemish\n",
      "176      tassel               adornment\n",
      "56        spool                  winder\n",
      "106    weakling                  person\n",
      "228      sequin               adornment\n",
      "90    tenseness               condition\n",
      "214      paging               utterance\n",
      "205     chowder                    soup\n",
      "86      lozenge                   candy\n",
      "89      cayenne                capsicum\n",
      "52     squealer               informant\n"
     ]
    }
   ],
   "source": [
    "hypernyms = []\n",
    "for row in lexops.iterrows():\n",
    "    wordnet_entries = wn.synsets(row[1].string, pos=wn.NOUN)\n",
    "    if len(wordnet_entries) > 0:\n",
    "        hypernym_entries = wn.synsets(row[1].string, pos=wn.NOUN)[0].hypernyms()\n",
    "        if len(hypernym_entries) > 0:\n",
    "            hypernym = hypernym_entries[0]\n",
    "            hypernyms.append(hypernym.name().split('.')[0])\n",
    "        else: \n",
    "            hypernyms.append(np.nan)\n",
    "    elif len(wordnet_entries) == 0: \n",
    "        hypernyms.append(np.nan)\n",
    "lexops['hypernym'] = hypernyms\n",
    "lexops_hypernym_available = lexops[~lexops['hypernym'].isna()]\n",
    "print(lexops_hypernym_available[['string','hypernym']].sample(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6d1a8157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rl05\\AppData\\Local\\Temp\\ipykernel_15588\\1353868061.py:16: DtypeWarning: Columns (11,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  resource_df = pd.read_csv(resource_fname, index_col=0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Only a column name can be used for the key in a dtype mappings argument. 'zipf' not found in columns.\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15588\\1353868061.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mresource\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresources\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mlexops_hypernym_available\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_stimulus_property\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlexops_hypernym_available\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mlexops_hypernym_available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15588\\1353868061.py\u001b[0m in \u001b[0;36mget_stimulus_property\u001b[1;34m(resource, dataframe)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mresource_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_fname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstim_property\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'hypernym'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mstim_property\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5877\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5878\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5879\u001b[1;33m                     raise KeyError(\n\u001b[0m\u001b[0;32m   5880\u001b[0m                         \u001b[1;34m\"Only a column name can be used for the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5881\u001b[0m                         \u001b[1;34m\"key in a dtype mappings argument. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Only a column name can be used for the key in a dtype mappings argument. 'zipf' not found in columns.\""
     ]
    }
   ],
   "source": [
    "resources = [('zipf','../resources/subtlex_uk.csv','LogFreq(Zipf)'),\n",
    "             ('CNC_M','../resources/brysbaert_etal_2014.csv','Conc_M'),\n",
    "             ('CNC_SD','../resources/brysbaert_etal_2014.csv','Conc_SD'),\n",
    "             ('imageability','../resources/scott_etal_2019.csv','IMAG'),\n",
    "             ('valence','../resources/scott_etal_2019.csv','VAL'),\n",
    "             ('AoA','../resources/kuperman_etal_2012.csv','Rating.Mean'),\n",
    "             ('RT','../resources/blp-items.xls','rt')]\n",
    "\n",
    "def get_stimulus_property(resource='', dataframe=None):\n",
    "    stim_property = resource[0]\n",
    "    resource_fname = resource[1]\n",
    "    col_name = resource[2]\n",
    "    if stim_property == 'RT':\n",
    "        resource_df = pd.read_excel(resource_fname, index_col=0)\n",
    "    else:\n",
    "        resource_df = pd.read_csv(resource_fname, index_col=0)\n",
    "    dataframe = dataframe.merge(resource_df[col_name].rename(stim_property), left_on='hypernym', right_index=True, how='left')\n",
    "    dataframe = dataframe.astype({stim_property:'float'})\n",
    "    return dataframe\n",
    "\n",
    "# count word length in number of letters\n",
    "lexops_hypernym_available['length'] = lexops_hypernym_available['string'].str.len()\n",
    "\n",
    "for resource in resources:\n",
    "    lexops_hypernym_available = get_stimulus_property(resource=resource, dataframe=lexops_hypernym_available)\n",
    "\n",
    "lexops_hypernym_available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f7d47f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
